# GIF-Blurrer
There are many cases of a neccessity where input videos/GIFs need to blur the images of actual people from within them. This could take a very long time to be manually done, but there is a machine learning tactic to solving this problem. A machine that could take each input frame of a GIF or video, find the coordinates of the faces of each frame, and blur that face could speed up this process. 

Luckily, there is a possible machine to do this, and it uses a model called MTCNN. MTCNN is a three staged neural network algorithm that can output coordinates for face boxes, along with the coordinates for eyes, mouth edges, and noses. The first stage is a Convultion Neural Network predicts potential face boxes, with many false predictions. The second stage is another CNN which uses the image outputs from the first stage and polishes it up, elimating many of the false predictions. The third stage has the most complex CNN of the algorithm, and refines even more predictions and adds the coordinates for the eyes, mouth edges, and noses. The MTCNN is trained off of getting the coordinates(x, y, width, and height) of the face boxes correct(a 4 dimensional vector), getting the coordinates of the other parts correct(a 10 dimensonal vector), and detecting whether the image has a face or not(a binary classification problem). The MTCNN is trained off of only the top 70% more useful samples of the dataset within each mini-batch to strengthen the model. 

The MTCNN algorithm is one of the most accurate algorithms for face detection. Using the face boxes, my GIF blurrer blurs from within each face box from each frame of the GIF. 
